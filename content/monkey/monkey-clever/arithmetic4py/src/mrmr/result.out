You have specified parameters: threshold=mu+/-0.00*sigma #fea=200 selection method=MID #maxVar=1000 #maxSample=1000000

Target classification variable (#1 column in the input data) has name=label 	entropy score=0.596

*** MaxRel features ***
Order 	 Fea 	 Name 	 Score
1 	 155 	 f154 	 0.027
2 	 154 	 f153 	 0.023
3 	 172 	 f171 	 0.021
4 	 164 	 f163 	 0.020
5 	 166 	 f165 	 0.019
6 	 181 	 f180 	 0.019
7 	 14 	 f13 	 0.019
8 	 167 	 f166 	 0.018
9 	 158 	 f157 	 0.016
10 	 127 	 f126 	 0.016
11 	 136 	 f135 	 0.015
12 	 46 	 f45 	 0.015
13 	 178 	 f177 	 0.015
14 	 137 	 f136 	 0.015
15 	 125 	 f124 	 0.015
16 	 49 	 f48 	 0.015
17 	 53 	 f52 	 0.015
18 	 131 	 f130 	 0.014
19 	 133 	 f132 	 0.014
20 	 2 	 f1 	 0.014
21 	 157 	 f156 	 0.014
22 	 117 	 f116 	 0.013
23 	 26 	 f25 	 0.013
24 	 130 	 f129 	 0.013
25 	 173 	 f172 	 0.013
26 	 182 	 f181 	 0.013
27 	 124 	 f123 	 0.013
28 	 122 	 f121 	 0.013
29 	 119 	 f118 	 0.013
30 	 76 	 f75 	 0.012
31 	 118 	 f117 	 0.012
32 	 168 	 f167 	 0.012
33 	 35 	 f34 	 0.011
34 	 37 	 f36 	 0.011
35 	 123 	 f122 	 0.011
36 	 25 	 f24 	 0.011
37 	 5 	 f4 	 0.011
38 	 126 	 f125 	 0.011
39 	 66 	 f65 	 0.010
40 	 7 	 f6 	 0.010
41 	 177 	 f176 	 0.010
42 	 95 	 f94 	 0.010
43 	 56 	 f55 	 0.009
44 	 29 	 f28 	 0.009
45 	 28 	 f27 	 0.009
46 	 184 	 f183 	 0.009
47 	 186 	 f185 	 0.009
48 	 101 	 f100 	 0.009
49 	 185 	 f184 	 0.009
50 	 105 	 f104 	 0.009
51 	 69 	 f68 	 0.008
52 	 68 	 f67 	 0.008
53 	 134 	 f133 	 0.008
54 	 36 	 f35 	 0.008
55 	 143 	 f142 	 0.008
56 	 145 	 f144 	 0.008
57 	 15 	 f14 	 0.008
58 	 79 	 f78 	 0.008
59 	 151 	 f150 	 0.008
60 	 52 	 f51 	 0.008
61 	 148 	 f147 	 0.007
62 	 98 	 f97 	 0.007
63 	 39 	 f38 	 0.007
64 	 170 	 f169 	 0.007
65 	 108 	 f107 	 0.007
66 	 111 	 f110 	 0.007
67 	 40 	 f39 	 0.007
68 	 67 	 f66 	 0.007
69 	 10 	 f9 	 0.007
70 	 64 	 f63 	 0.007
71 	 55 	 f54 	 0.007
72 	 82 	 f81 	 0.006
73 	 176 	 f175 	 0.006
74 	 83 	 f82 	 0.006
75 	 70 	 f69 	 0.006
76 	 65 	 f64 	 0.006
77 	 146 	 f145 	 0.006
78 	 6 	 f5 	 0.006
79 	 102 	 f101 	 0.006
80 	 20 	 f19 	 0.006
81 	 149 	 f148 	 0.006
82 	 96 	 f95 	 0.006
83 	 99 	 f98 	 0.006
84 	 113 	 f112 	 0.006
85 	 62 	 f61 	 0.006
86 	 84 	 f83 	 0.006
87 	 163 	 f162 	 0.006
88 	 139 	 f138 	 0.006
89 	 169 	 f168 	 0.006
90 	 85 	 f84 	 0.006
91 	 16 	 f15 	 0.006
92 	 116 	 f115 	 0.005
93 	 94 	 f93 	 0.005
94 	 19 	 f18 	 0.005
95 	 115 	 f114 	 0.005
96 	 109 	 f108 	 0.005
97 	 43 	 f42 	 0.005
98 	 4 	 f3 	 0.005
99 	 162 	 f161 	 0.005
100 	 38 	 f37 	 0.005
101 	 110 	 f109 	 0.005
102 	 61 	 f60 	 0.005
103 	 103 	 f102 	 0.005
104 	 112 	 f111 	 0.005
105 	 100 	 f99 	 0.005
106 	 48 	 f47 	 0.004
107 	 33 	 f32 	 0.004
108 	 41 	 f40 	 0.004
109 	 97 	 f96 	 0.004
110 	 13 	 f12 	 0.004
111 	 107 	 f106 	 0.004
112 	 174 	 f173 	 0.004
113 	 104 	 f103 	 0.004
114 	 3 	 f2 	 0.004
115 	 60 	 f59 	 0.004
116 	 156 	 f155 	 0.004
117 	 75 	 f74 	 0.004
118 	 86 	 f85 	 0.003
119 	 140 	 f139 	 0.003
120 	 71 	 f70 	 0.003
121 	 106 	 f105 	 0.003
122 	 80 	 f79 	 0.003
123 	 22 	 f21 	 0.003
124 	 11 	 f10 	 0.003
125 	 114 	 f113 	 0.003
126 	 32 	 f31 	 0.003
127 	 161 	 f160 	 0.003
128 	 59 	 f58 	 0.003
129 	 72 	 f71 	 0.003
130 	 77 	 f76 	 0.003
131 	 47 	 f46 	 0.003
132 	 34 	 f33 	 0.002
133 	 74 	 f73 	 0.002
134 	 159 	 f158 	 0.002
135 	 132 	 f131 	 0.002
136 	 30 	 f29 	 0.002
137 	 17 	 f16 	 0.002
138 	 8 	 f7 	 0.002
139 	 57 	 f56 	 0.002
140 	 51 	 f50 	 0.001
141 	 45 	 f44 	 0.001
142 	 138 	 f137 	 0.001
143 	 58 	 f57 	 0.001
144 	 189 	 f188 	 0.001
145 	 192 	 f191 	 0.001
146 	 141 	 f140 	 0.001
147 	 191 	 f190 	 0.001
148 	 23 	 f22 	 0.001
149 	 31 	 f30 	 0.001
150 	 128 	 f127 	 0.001
151 	 44 	 f43 	 0.001
152 	 63 	 f62 	 0.001
153 	 1 	 f0 	 0.001
154 	 27 	 f26 	 0.000
155 	 150 	 f149 	 0.000
156 	 81 	 f80 	 0.000
157 	 129 	 f128 	 0.000
158 	 179 	 f178 	 0.000
159 	 142 	 f141 	 0.000
160 	 120 	 f119 	 0.000
161 	 190 	 f189 	 0.000
162 	 165 	 f164 	 0.000
163 	 12 	 f11 	 0.000
164 	 121 	 f120 	 0.000
165 	 54 	 f53 	 0.000
166 	 73 	 f72 	 0.000
167 	 9 	 f8 	 0.000
168 	 89 	 f88 	 0.000
169 	 90 	 f89 	 0.000
170 	 187 	 f186 	 0.000
171 	 171 	 f170 	 0.000
172 	 50 	 f49 	 0.000
173 	 188 	 f187 	 0.000
174 	 87 	 f86 	 0.000
175 	 175 	 f174 	 0.000
176 	 153 	 f152 	 0.000
177 	 193 	 f192 	 0.000
178 	 88 	 f87 	 0.000
179 	 78 	 f77 	 0.000
180 	 147 	 f146 	 0.000
181 	 180 	 f179 	 0.000
182 	 194 	 f193 	 0.000
183 	 160 	 f159 	 0.000
184 	 18 	 f17 	 0.000
185 	 152 	 f151 	 0.000
186 	 92 	 f91 	 0.000
187 	 183 	 f182 	 0.000
188 	 42 	 f41 	 0.000
189 	 135 	 f134 	 0.000
190 	 24 	 f23 	 0.000
191 	 91 	 f90 	 0.000
192 	 21 	 f20 	 0.000
193 	 144 	 f143 	 0.000
194 	 93 	 f92 	 0.000

*** mRMR features *** 
Order 	 Fea 	 Name 	 Score
1 	 155 	 f154 	 0.027
2 	 127 	 f126 	 0.015
3 	 122 	 f121 	 0.007
4 	 185 	 f184 	 0.008
5 	 37 	 f36 	 0.007
6 	 39 	 f38 	 0.006
7 	 26 	 f25 	 0.002
8 	 70 	 f69 	 0.002
9 	 80 	 f79 	 0.000
10 	 46 	 f45 	 0.001
11 	 11 	 f10 	 0.000
12 	 14 	 f13 	 0.001
13 	 41 	 f40 	 0.000
14 	 144 	 f143 	 0.000
15 	 93 	 f92 	 0.000
16 	 114 	 f113 	 0.000
17 	 195 	 f194 	 0.000
18 	 171 	 f170 	 -0.000
19 	 42 	 f41 	 -0.000
20 	 133 	 f132 	 0.000
21 	 172 	 f171 	 0.001
22 	 38 	 f37 	 0.000
23 	 16 	 f15 	 0.000
24 	 120 	 f119 	 -0.001
25 	 77 	 f76 	 -0.001
26 	 182 	 f181 	 -0.000
27 	 40 	 f39 	 -0.001
28 	 76 	 f75 	 -0.000
29 	 53 	 f52 	 -0.001
30 	 132 	 f131 	 -0.001
31 	 2 	 f1 	 -0.001
32 	 129 	 f128 	 -0.001
33 	 143 	 f142 	 -0.001
34 	 15 	 f14 	 -0.002
35 	 181 	 f180 	 -0.002
36 	 73 	 f72 	 -0.002
37 	 63 	 f62 	 -0.002
38 	 164 	 f163 	 -0.002
39 	 78 	 f77 	 -0.002
40 	 34 	 f33 	 -0.003
41 	 128 	 f127 	 -0.003
42 	 81 	 f80 	 -0.004
43 	 193 	 f192 	 -0.005
44 	 20 	 f19 	 -0.005
45 	 3 	 f2 	 -0.005
46 	 85 	 f84 	 -0.005
47 	 49 	 f48 	 -0.005
48 	 36 	 f35 	 -0.006
49 	 125 	 f124 	 -0.006
50 	 180 	 f179 	 -0.006
51 	 12 	 f11 	 -0.006
52 	 158 	 f157 	 -0.006
53 	 165 	 f164 	 -0.008
54 	 67 	 f66 	 -0.008
55 	 19 	 f18 	 -0.008
56 	 175 	 f174 	 -0.008
57 	 82 	 f81 	 -0.008
58 	 74 	 f73 	 -0.008
59 	 35 	 f34 	 -0.008
60 	 86 	 f85 	 -0.009
61 	 145 	 f144 	 -0.009
62 	 166 	 f165 	 -0.009
63 	 91 	 f90 	 -0.009
64 	 33 	 f32 	 -0.009
65 	 186 	 f185 	 -0.009
66 	 79 	 f78 	 -0.010
67 	 142 	 f141 	 -0.010
68 	 154 	 f153 	 -0.010
69 	 178 	 f177 	 -0.010
70 	 75 	 f74 	 -0.010
71 	 1 	 f0 	 -0.010
72 	 32 	 f31 	 -0.011
73 	 131 	 f130 	 -0.011
74 	 13 	 f12 	 -0.011
75 	 56 	 f55 	 -0.011
76 	 28 	 f27 	 -0.012
77 	 24 	 f23 	 -0.012
78 	 72 	 f71 	 -0.012
79 	 135 	 f134 	 -0.012
80 	 183 	 f182 	 -0.012
81 	 192 	 f191 	 -0.013
82 	 9 	 f8 	 -0.013
83 	 43 	 f42 	 -0.013
84 	 177 	 f176 	 -0.013
85 	 95 	 f94 	 -0.013
86 	 84 	 f83 	 -0.013
87 	 29 	 f28 	 -0.014
88 	 188 	 f187 	 -0.014
89 	 176 	 f175 	 -0.015
90 	 52 	 f51 	 -0.014
91 	 130 	 f129 	 -0.015
92 	 30 	 f29 	 -0.015
93 	 184 	 f183 	 -0.016
94 	 68 	 f67 	 -0.016
95 	 157 	 f156 	 -0.016
96 	 92 	 f91 	 -0.016
97 	 71 	 f70 	 -0.016
98 	 7 	 f6 	 -0.016
99 	 121 	 f120 	 -0.016
100 	 134 	 f133 	 -0.017
101 	 23 	 f22 	 -0.017
102 	 167 	 f166 	 -0.017
103 	 8 	 f7 	 -0.018
104 	 173 	 f172 	 -0.018
105 	 163 	 f162 	 -0.018
106 	 25 	 f24 	 -0.018
107 	 139 	 f138 	 -0.018
108 	 62 	 f61 	 -0.019
109 	 64 	 f63 	 -0.019
110 	 17 	 f16 	 -0.019
111 	 189 	 f188 	 -0.019
112 	 50 	 f49 	 -0.020
113 	 179 	 f178 	 -0.020
114 	 146 	 f145 	 -0.020
115 	 10 	 f9 	 -0.021
116 	 83 	 f82 	 -0.021
117 	 55 	 f54 	 -0.021
118 	 66 	 f65 	 -0.021
119 	 169 	 f168 	 -0.022
120 	 89 	 f88 	 -0.022
121 	 51 	 f50 	 -0.022
122 	 137 	 f136 	 -0.022
123 	 148 	 f147 	 -0.024
124 	 174 	 f173 	 -0.024
125 	 141 	 f140 	 -0.024
126 	 6 	 f5 	 -0.024
127 	 105 	 f104 	 -0.024
128 	 31 	 f30 	 -0.025
129 	 59 	 f58 	 -0.025
130 	 194 	 f193 	 -0.025
131 	 149 	 f148 	 -0.026
132 	 65 	 f64 	 -0.025
133 	 4 	 f3 	 -0.026
134 	 61 	 f60 	 -0.026
135 	 117 	 f116 	 -0.026
136 	 22 	 f21 	 -0.027
137 	 87 	 f86 	 -0.027
138 	 44 	 f43 	 -0.027
139 	 5 	 f4 	 -0.027
140 	 162 	 f161 	 -0.028
141 	 168 	 f167 	 -0.028
142 	 69 	 f68 	 -0.029
143 	 47 	 f46 	 -0.029
144 	 187 	 f186 	 -0.030
145 	 138 	 f137 	 -0.030
146 	 151 	 f150 	 -0.030
147 	 116 	 f115 	 -0.030
148 	 191 	 f190 	 -0.030
149 	 18 	 f17 	 -0.031
150 	 57 	 f56 	 -0.032
151 	 88 	 f87 	 -0.032
152 	 109 	 f108 	 -0.032
153 	 60 	 f59 	 -0.033
154 	 21 	 f20 	 -0.033
155 	 118 	 f117 	 -0.033
156 	 161 	 f160 	 -0.034
157 	 170 	 f169 	 -0.034
158 	 190 	 f189 	 -0.034
159 	 48 	 f47 	 -0.035
160 	 140 	 f139 	 -0.035
161 	 90 	 f89 	 -0.036
162 	 153 	 f152 	 -0.036
163 	 27 	 f26 	 -0.037
164 	 124 	 f123 	 -0.037
165 	 45 	 f44 	 -0.037
166 	 101 	 f100 	 -0.038
167 	 152 	 f151 	 -0.039
168 	 54 	 f53 	 -0.039
169 	 115 	 f114 	 -0.040
170 	 58 	 f57 	 -0.041
171 	 159 	 f158 	 -0.043
172 	 98 	 f97 	 -0.043
173 	 119 	 f118 	 -0.045
174 	 156 	 f155 	 -0.045
175 	 94 	 f93 	 -0.046
176 	 136 	 f135 	 -0.049
177 	 102 	 f101 	 -0.050
178 	 147 	 f146 	 -0.051
179 	 150 	 f149 	 -0.052
180 	 107 	 f106 	 -0.054
181 	 126 	 f125 	 -0.054
182 	 160 	 f159 	 -0.054
183 	 100 	 f99 	 -0.057
184 	 106 	 f105 	 -0.059
185 	 123 	 f122 	 -0.060
186 	 103 	 f102 	 -0.063
187 	 104 	 f103 	 -0.066
188 	 110 	 f109 	 -0.068
189 	 96 	 f95 	 -0.072
190 	 111 	 f110 	 -0.075
191 	 113 	 f112 	 -0.077
192 	 99 	 f98 	 -0.080
193 	 112 	 f111 	 -0.083
194 	 108 	 f107 	 -0.086
195 	 97 	 f96 	 -0.091


 *** This program and the respective minimum Redundancy Maximum Relevance (mRMR) 
     algorithm were developed by Hanchuan Peng <hanchuan.peng@gmail.com>for
     the paper 
     "Feature selection based on mutual information: criteria of 
      max-dependency, max-relevance, and min-redundancy,"
      Hanchuan Peng, Fuhui Long, and Chris Ding, 
      IEEE Transactions on Pattern Analysis and Machine Intelligence,
      Vol. 27, No. 8, pp.1226-1238, 2005.

